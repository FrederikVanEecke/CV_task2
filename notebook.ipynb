{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b47b15de-64a5-4fa9-a688-23d3efa9a2f4",
    "_uuid": "0cc385a7-98f6-4883-96eb-7b89c7c9aa1c",
    "papermill": {
     "duration": 0.010809,
     "end_time": "2021-03-29T09:04:17.390934",
     "exception": false,
     "start_time": "2021-03-29T09:04:17.380125",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"width:100%; height:140px\">\n",
    "    <img src=\"https://www.kuleuven.be/internationaal/thinktank/fotos-en-logos/ku-leuven-logo.png/image_preview\" width = 300px, heigh = auto align=left>\n",
    "</div>\n",
    "\n",
    "\n",
    "KUL H02A5a Computer Vision: Group Assignment 1\n",
    "---------------------------------------------------------------\n",
    "Student numbers: <span style=\"color:red\">r0611202, r0633222, r3, r4, r5</span>. (fill in your student numbers!)\n",
    "\n",
    "In this group assignment your team will delve into some deep learning applications for computer vision. The assignment will be delivered in the same groups from *Group assignment 0* and you start from this template notebook. The notebook you submit for grading is the last notebook you submit in the [Kaggle competition](https://www.kaggle.com/t/b7a2a8743bd842ca9ac93ae91cbc8d9f) prior to the deadline on **Tuesday 18 May 23:59**. Closely follow [these instructions](https://github.com/gourie/kaggle_inclass) for joining the competition, sharing your notebook with the TAs and making a valid notebook submission to the competition. A notebook submission not only produces a *submission.csv* file that is used to calculate your competition score, it also runs the entire notebook and saves its output as if it were a report. This way it becomes an all-in-one-place document for the TAs to review. As such, please make sure that your final submission notebook is self-contained and fully documented (e.g. provide strong arguments for the design choices that you make). Most likely, this notebook format is not appropriate to run all your experiments at submission time (e.g. the training of CNNs is a memory hungry and time consuming process; due to limited Kaggle resources). It can be a good idea to distribute your code otherwise and only summarize your findings, together with your final predictions, in the submission notebook. For example, you can substitute experiments with some text and figures that you have produced \"offline\" (e.g. learning curves and results on your internal validation set or even the test set for different architectures, pre-processing pipelines, etc). We advise you to first go through the PDF of this assignment entirely before you really start. Then, it can be a good idea to go through this notebook and use it as your first notebook submission to the competition. You can make use of the *Group assignment 1* forum/discussion board on Toledo if you have any questions. Good luck and have fun!\n",
    "\n",
    "---------------------------------------------------------------\n",
    "NOTES:\n",
    "* This notebook is just a template. Please keep the five main sections, but feel free to adjust further in any way you please!\n",
    "* Clearly indicate the improvements that you make! You can for instance use subsections like: *3.1. Improvement: applying loss function f instead of g*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "35358cfb-b13d-4277-8dd5-4e663c8cd775",
    "_uuid": "3b40b846-d7da-46d8-b354-c6d5c5ded56e",
    "papermill": {
     "duration": 0.009414,
     "end_time": "2021-03-29T09:04:17.410239",
     "exception": false,
     "start_time": "2021-03-29T09:04:17.400825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Overview\n",
    "This assignment consists of *three main parts* for which we expect you to provide code and extensive documentation in the notebook:\n",
    "* Image classification (Sect. 2)\n",
    "* Semantic segmentation (Sect. 3)\n",
    "* Adversarial attacks (Sect. 4)\n",
    "\n",
    "In the first part, you will train an end-to-end neural network for image classification. In the second part, you will do the same for semantic segmentation. For these two tasks we expect you to put a significant effort into optimizing performance and as such competing with fellow students via the Kaggle competition. In the third part, you will try to find and exploit the weaknesses of your classification and/or segmentation network. For the latter there is no competition format, but we do expect you to put significant effort in achieving good performance on the self-posed goal for that part. Finally, we ask you to reflect and produce an overall discussion with links to the lectures and \"real world\" computer vision (Sect. 5). It is important to note that only a small part of the grade will reflect the actual performance of your networks. However, we do expect all things to work! In general, we will evaluate the correctness of your approach and your understanding of what you have done that you demonstrate in the descriptions and discussions in the final notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009248,
     "end_time": "2021-03-29T09:04:17.429068",
     "exception": false,
     "start_time": "2021-03-29T09:04:17.419820",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.1 Deep learning resources\n",
    "If you did not yet explore this in *Group assignment 0 (Sect. 2)*, we recommend using the TensorFlow and/or Keras library for building deep learning models. You can find a nice crash course [here](https://colab.research.google.com/drive/1UCJt8EYjlzCs1H1d1X0iDGYJsHKwu-NO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T19:28:31.852850Z",
     "start_time": "2021-04-26T19:28:30.417480Z"
    },
    "_cell_guid": "7ddf657a-b938-4a49-87dc-b0db9af9156d",
    "_uuid": "c65ea4f1-cc90-408f-b8e0-7c7399ec7e21",
    "execution": {
     "iopub.execute_input": "2021-03-29T09:04:17.454356Z",
     "iopub.status.busy": "2021-03-29T09:04:17.453623Z",
     "iopub.status.idle": "2021-03-29T09:04:23.936131Z",
     "shell.execute_reply": "2021-03-29T09:04:23.936637Z"
    },
    "papermill": {
     "duration": 6.498173,
     "end_time": "2021-03-29T09:04:23.936979",
     "exception": false,
     "start_time": "2021-03-29T09:04:17.438806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os \n",
    "import multiprocessing\n",
    "import wandb\n",
    "# !pip install wandb -qqq\n",
    "from wandb.keras import WandbCallback\n",
    "import cv2\n",
    "from ipywidgets import fixed, interact \n",
    "import ipywidgets\n",
    "from albumentations import (\n",
    "    Compose, HorizontalFlip, CLAHE, HueSaturationValue,\n",
    "    RandomBrightness, RandomContrast, RandomGamma,\n",
    "    ToFloat, ShiftScaleRotate, RandomBrightnessContrast, RandomCrop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.executable\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009505,
     "end_time": "2021-03-29T09:04:23.956792",
     "exception": false,
     "start_time": "2021-03-29T09:04:23.947287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.2 PASCAL VOC 2009\n",
    "For this project you will be using the [PASCAL VOC 2009](http://host.robots.ox.ac.uk/pascal/VOC/voc2009/index.html) dataset. This dataset consists of colour images of various scenes with different object classes (e.g. animal: *bird, cat, ...*; vehicle: *aeroplane, bicycle, ...*), totalling 20 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T19:28:39.826575Z",
     "start_time": "2021-04-26T19:28:33.696577Z"
    },
    "_cell_guid": "1ce67f49-6bf6-4e5c-b5e4-576e893616a9",
    "_uuid": "3b1c5fbb-757f-4349-b224-e281c540e1ad",
    "execution": {
     "iopub.execute_input": "2021-03-29T09:04:23.987073Z",
     "iopub.status.busy": "2021-03-29T09:04:23.984740Z",
     "iopub.status.idle": "2021-03-29T09:04:54.774578Z",
     "shell.execute_reply": "2021-03-29T09:04:54.775506Z"
    },
    "papermill": {
     "duration": 30.809201,
     "end_time": "2021-03-29T09:04:54.775815",
     "exception": false,
     "start_time": "2021-03-29T09:04:23.966614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading the training data\n",
    "train_df = pd.read_csv('data/train/train_set.csv', index_col=\"Id\")\n",
    "labels = train_df.columns\n",
    "train_df[\"img\"] = [np.load('data/train/img/train_{}.npy'.format(idx)) for idx, _ in train_df.iterrows()]\n",
    "train_df[\"seg\"] = [np.load('data/train/seg/train_{}.npy'.format(idx)) for idx, _ in train_df.iterrows()]\n",
    "print(\"The training set contains {} examples.\".format(len(train_df)))\n",
    "\n",
    "# Show some examples\n",
    "fig, axs = plt.subplots(2, 20, figsize=(10 * 20, 10 * 2))\n",
    "for i, label in enumerate(labels):\n",
    "    df = train_df.loc[train_df[label] == 1]\n",
    "    axs[0, i].imshow(df.iloc[0][\"img\"], vmin=0, vmax=255)\n",
    "    axs[0, i].set_title(\"\\n\".join(label for label in labels if df.iloc[0][label] == 1), fontsize=40)\n",
    "    axs[0, i].axis(\"off\")\n",
    "    axs[1, i].imshow(df.iloc[0][\"seg\"], vmin=0, vmax=20)  # with the absolute color scale it will be clear that the arrays in the \"seg\" column are label maps (labels in [0, 20])\n",
    "    axs[1, i].axis(\"off\")\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "# The training dataframe contains for each image 20 columns with the ground truth classification labels and 20 column with the ground truth segmentation maps for each class\n",
    "train_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T19:29:30.108848Z",
     "start_time": "2021-04-26T19:29:28.160299Z"
    },
    "execution": {
     "iopub.execute_input": "2021-03-29T09:04:55.411245Z",
     "iopub.status.busy": "2021-03-29T09:04:55.405662Z",
     "iopub.status.idle": "2021-03-29T09:05:15.866350Z",
     "shell.execute_reply": "2021-03-29T09:05:15.865480Z"
    },
    "papermill": {
     "duration": 20.776375,
     "end_time": "2021-03-29T09:05:15.866678",
     "exception": false,
     "start_time": "2021-03-29T09:04:55.090303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading the test data\n",
    "test_df = pd.read_csv('data/test/test_set.csv', index_col=\"Id\")\n",
    "test_df[\"img\"] = [np.load('data/test/img/test_{}.npy'.format(idx)) for idx, _ in test_df.iterrows()]\n",
    "test_df[\"seg\"] = [-1 * np.ones(img.shape[:2], dtype=np.int8) for img in test_df[\"img\"]]\n",
    "print(\"The test set contains {} examples.\".format(len(test_df)))\n",
    "\n",
    "# The test dataframe is similar to the training dataframe, but here the values are -1 --> your task is to fill in these as good as possible in Sect. 2 and Sect. 3; in Sect. 6 this dataframe is automatically transformed in the submission CSV!\n",
    "test_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.295407,
     "end_time": "2021-03-29T09:05:16.448937",
     "exception": false,
     "start_time": "2021-03-29T09:05:16.153530",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.3 Your Kaggle submission\n",
    "Your filled test dataframe (during Sect. 2 and Sect. 3) must be converted to a submission.csv with two rows per example (one for classification and one for segmentation) and with only a single prediction column (the multi-class/label predictions running length encoded). You don't need to edit this section. Just make sure to call this function at the right position in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T19:30:30.019622Z",
     "start_time": "2021-04-26T19:30:30.013827Z"
    },
    "execution": {
     "iopub.execute_input": "2021-03-29T09:05:17.026801Z",
     "iopub.status.busy": "2021-03-29T09:05:17.024925Z",
     "iopub.status.idle": "2021-03-29T09:05:17.042851Z",
     "shell.execute_reply": "2021-03-29T09:05:17.040634Z"
    },
    "papermill": {
     "duration": 0.293321,
     "end_time": "2021-03-29T09:05:17.043036",
     "exception": false,
     "start_time": "2021-03-29T09:05:16.749715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _rle_encode(img):\n",
    "    \"\"\"\n",
    "    Kaggle requires RLE encoded predictions for computation of the Dice score (https://www.kaggle.com/lifa08/run-length-encode-and-decode)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img: np.ndarray - binary img array\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    rle: String - running length encoded version of img\n",
    "    \"\"\"\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    rle = ' '.join(str(x) for x in runs)\n",
    "    return rle\n",
    "\n",
    "def generate_submission(df):\n",
    "    \"\"\"\n",
    "    Make sure to call this function once after you completed Sect. 2 and Sect. 3! It transforms and writes your test dataframe into a submission.csv file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame - filled dataframe that needs to be converted\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    submission_df: pd.DataFrame - df in submission format.\n",
    "    \"\"\"\n",
    "    df_dict = {\"Id\": [], \"Predicted\": []}\n",
    "    for idx, _ in df.iterrows():\n",
    "        df_dict[\"Id\"].append(f\"{idx}_classification\")\n",
    "        df_dict[\"Predicted\"].append(_rle_encode(np.array(df.loc[idx, labels])))\n",
    "        df_dict[\"Id\"].append(f\"{idx}_segmentation\")\n",
    "        df_dict[\"Predicted\"].append(_rle_encode(np.array([df.loc[idx, \"seg\"] == j + 1 for j in range(len(labels))])))\n",
    "    \n",
    "    submission_df = pd.DataFrame(data=df_dict, dtype=str).set_index(\"Id\")\n",
    "    submission_df.to_csv(\"submission.csv\")\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset class for classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Classification(object): \n",
    "    \"\"\"\n",
    "     A dataset class usefull when training a classification model. \n",
    "    \"\"\"\n",
    "    def __init__(self, config): \n",
    "        self.config = config\n",
    "        \n",
    "        # set labels in a usefull format\n",
    "        self._classification_labels()\n",
    "        \n",
    "        # initialize\n",
    "        self.initialize()\n",
    "        \n",
    "        # to keep track of sampling\n",
    "        self.sampling_check = np.zeros(20)\n",
    "        self.times_sampled = 0\n",
    "        \n",
    "        \n",
    "    def initialize(self):\n",
    "        \"\"\"\n",
    "            Performs necessary thingss\n",
    "        \"\"\"\n",
    "        self.train_data_path = 'data/train/img'\n",
    "        self.test_data_path = 'data/test/img'\n",
    "        \n",
    "        # count nbr of files within data set. \n",
    "        self.nbr_of_train_images = len(os.listdir(self.train_data_path))\n",
    "        self.nbr_of_test_images = len(os.listdir(self.test_data_path))\n",
    "        \n",
    "        # prepare train/validation split \n",
    "        train_fraction = self.config['train_fraction']\n",
    "        r_idx=np.random.permutation(self.nbr_of_train_images)\n",
    "        \n",
    "        self.train_indices = r_idx[:int(train_fraction*self.nbr_of_train_images)]\n",
    "        self.train_sample_probs = self.probabilities[self.train_indices]/np.sum(self.probabilities[self.train_indices])\n",
    "        \n",
    "        self.validation_indices = r_idx[int(train_fraction*self.nbr_of_train_images):]\n",
    "        self.validation_sample_probs = self.probabilities[self.validation_indices]/np.sum(self.probabilities[self.validation_indices])\n",
    "        \n",
    "        print('Found {} train images'.format(self.nbr_of_train_images))\n",
    "        print('- {} used for training, {} used for validating'.format(len(self.train_indices), len(self.validation_indices)))\n",
    "        print('Found {} test images'.format(self.nbr_of_test_images))\n",
    "        \n",
    "        if self.config['augmentation']: \n",
    "            print('Including augmentation when training data is generated')\n",
    "        self.augment = Compose([\n",
    "                        #RandomCrop(width=self.config['input_shape'][0], height=self.config['input_shape'][0]),\n",
    "                        HorizontalFlip(p=0.5),\n",
    "                        RandomContrast(limit=0.1,p=0.25),\n",
    "                        #RandomGamma(gamma_limit=(80, 120), p=0.5),\n",
    "                        RandomBrightness(limit=0.15, p=0.5),\n",
    "                        RandomBrightnessContrast(p=0.2),\n",
    "                        HueSaturationValue(hue_shift_limit=1.5, sat_shift_limit=5,\n",
    "                                           val_shift_limit=2.5, p=.7),\n",
    "                        # CLAHE(p=1.0, clip_limit=2.0),\n",
    "                        ShiftScaleRotate(\n",
    "                            shift_limit=0.1, scale_limit=0.1, \n",
    "                            rotate_limit=15, border_mode=cv2.BORDER_REFLECT_101, p=0.8), \n",
    "                    ])\n",
    "    \n",
    "        self.preprocessor = lambda x: x #defualt preprocessor does nothing \n",
    "        \n",
    "    def get_test_set_size(self): \n",
    "        return self.nbr_of_test_images\n",
    "    def get_train_set_size(self): \n",
    "        return self.nbr_of_train_images\n",
    "        \n",
    "    def reshape(self,im): \n",
    "        return cv2.resize(im, self.config['input_shape'])\n",
    "        \n",
    "    def _classification_labels(self): \n",
    "        \"\"\"\n",
    "            Get the classification labels \n",
    "        \"\"\"\n",
    "        # label names \n",
    "        train_df = pd.read_csv('data/train/train_set.csv', index_col=\"Id\")\n",
    "        self.label_names = train_df.columns.to_numpy()\n",
    "        \n",
    "        # get rid of pandas frame \n",
    "        self.labels = train_df.to_numpy() # each row corresponds to label\n",
    "        \n",
    "        # instances per class\n",
    "        absolute_nbr_of_instances_per_class = np.sum(self.labels,axis=0)\n",
    "        # get array with label name for each image \n",
    "        self.class_name_per_image = list()\n",
    "        probabilities = list()\n",
    "        total_class_prob = 1/20*np.ones(20)\n",
    "        #total_class_prob[14]=0\n",
    "        for row in self.labels: #can probably be done more eligant\n",
    "            idx = np.where(row==1)[0]\n",
    "            if 14 in idx:\n",
    "                idx=14\n",
    "            else:\n",
    "                idx=idx[0]\n",
    "            probabilities.append(total_class_prob[idx]/absolute_nbr_of_instances_per_class[idx])\n",
    "            self.class_name_per_image.append(self.label_names[idx])\n",
    "        \n",
    "        \n",
    "        # make sure total probability sums to 1\n",
    "        if self.config['uniform_sample_probabilities']:\n",
    "            self.probabilities = np.ones(np.array(probabilities).shape)/len(probabilities) # uniform sampling\n",
    "        else:\n",
    "            self.probabilities = np.array(probabilities)/np.sum(probabilities) # sampling based on distribution of classes in trainning data\n",
    "            \n",
    "            \n",
    "    def feed_preprocess_function(self, preprocessor): \n",
    "        \"\"\"\n",
    "            Each network needs it's batches preprocessed in some manner. Feed this function to the Dataset object \n",
    "            who will call it when asking for batches.\n",
    "            \n",
    "            The preprocessor takes \n",
    "        \"\"\"\n",
    "        self.preprocessor = preprocessor\n",
    "    \n",
    "    def prepare_image(self, image): \n",
    "        \"\"\"\n",
    "            Function that performs all necessary steps from input image to image passed during trainnig. \n",
    "            This method should be overwritten depending on the model used.\n",
    "        \"\"\"\n",
    "        h,w,c=image.shape\n",
    "        # resize manually, when augmentation is turned on a random crop will be done 100% of times.\n",
    "        #if not self.config['augmentation'] or h < self.config['input_shape'][0]or w < self.config['input_shape'][1]:\n",
    "        image = self.reshape(image)\n",
    "\n",
    "        # augment if augmentation is turned on \n",
    "        if self.config['augmentation']:\n",
    "#             print('Augmentation enabled: check if combination of preprocessor and augmentation makes sence')\n",
    "            image=self.augment(image=image)[\"image\"]\n",
    "        \n",
    "        # preprocess \n",
    "        image = self.preprocessor(image)\n",
    "        return image\n",
    "    \n",
    "    def prepare_test_image(self, image): \n",
    "        \"\"\"\n",
    "             Same as prepare_image but without augmentation\n",
    "        \"\"\"\n",
    "        h,w,c=image.shape\n",
    "        # resize manually, when augmentation is turned on a random crop will be done 100% of times.\n",
    "        #if not self.config['augmentation'] or h < self.config['input_shape'][0]or w < self.config['input_shape'][1]:\n",
    "        image = self.reshape(image)\n",
    "        \n",
    "        # preprocess \n",
    "        image = self.preprocessor(image)\n",
    "        return image\n",
    "    \n",
    "    def view_preprocessed_image(self, image_id, option='train'): \n",
    "        \"\"\"\n",
    "            Shows an image as it is passed during training/testing of the network. \n",
    "            image_id \n",
    "        \"\"\"\n",
    "        assert hasattr(self, 'preprocessor'), 'set a preprocessor function before using this.'\n",
    "        \n",
    "        # get image \n",
    "        if option=='train':\n",
    "            # get image \n",
    "            real_image = np.load('data/train/img/train_{}.npy'.format(image_id) )\n",
    "            label = self.class_name_per_image[image_id]\n",
    "        else: \n",
    "            real_image = np.load('data/test/img/test_{}.npy'.format(image_id) )\n",
    "            label = 'unknown'\n",
    "            \n",
    "        image=np.copy(real_image)\n",
    "        \n",
    "        image = self.prepare_image(image)\n",
    "        \n",
    "    \n",
    "    \n",
    "        # print some info \n",
    "        print('original image:')\n",
    "        print('-original_shape:', real_image.shape)\n",
    "        print('-dtype:', real_image.dtype)\n",
    "        print('-min value:', np.min(real_image))\n",
    "        print('-max value:', np.max(real_image))\n",
    "        \n",
    "        print('final image:')\n",
    "        print('-final shape:', image.shape)\n",
    "        print('-dtype:', image.dtype)\n",
    "        print('-min value:', np.min(image))\n",
    "        print('-max value:', np.max(image))\n",
    "        \n",
    "        \n",
    "        # show figure \n",
    "        fig, axes = plt.subplots(1,2, figsize=(30,15))\n",
    "        axes[0].imshow(real_image)\n",
    "        axes[0].set_title('Original image', fontsize=50)\n",
    "        \n",
    "        axes[1].imshow(image) # clip it to [0,1] range\n",
    "        axes[1].set_title('preprocessed_image', fontsize=50)\n",
    "        \n",
    "        plt.suptitle('label: {}'.format(label), fontsize=50)\n",
    "        fig.show()\n",
    "        \n",
    "    def view_possible_augmentations(self, image_id): \n",
    "        fig, axes = plt.subplots(4,4, figsize=(60,30))\n",
    "        real_image = np.load('data/train/img/train_{}.npy'.format(image_id) )\n",
    "        plt.suptitle('original image is on the top left', fontsize=50)\n",
    "        for ax in axes.flat: \n",
    "            ax.imshow(self.augment(image=real_image)[\"image\"])\n",
    "            ax.axis('off')\n",
    "        axes[0,0] = plt.imshow(real_image)\n",
    "        fig.show()\n",
    "        \n",
    "        \n",
    "    \n",
    "    def train_generator(self,batch_size):\n",
    "        \"\"\"\n",
    "            generator that will feed training batches during training \n",
    "        \"\"\"\n",
    "        inputs = []\n",
    "        targets = []\n",
    "        batchcount = 0\n",
    "        while True:\n",
    "#             for image_id in self.train_indices:\n",
    "            image_id = np.random.choice(self.train_indices, p=self.train_sample_probs)\n",
    "            # sample real image\n",
    "            real_image = np.load('data/train/img/train_{}.npy'.format(image_id) )\n",
    "\n",
    "            image = self.prepare_image(np.copy(real_image))\n",
    "            inputs.append(image)\n",
    "\n",
    "            # get corresponding label \n",
    "            targets.append(self.labels[image_id])\n",
    "            \n",
    "            self.sampling_check+=self.labels[image_id]\n",
    "            self.times_sampled+=1\n",
    "            \n",
    "\n",
    "            batchcount += 1\n",
    "            if batchcount > batch_size:\n",
    "                X = np.array(inputs)\n",
    "                y = np.array(targets, dtype=np.uint8)\n",
    "                yield (X, y)\n",
    "                inputs = []\n",
    "                targets = []\n",
    "                batchcount = 0\n",
    "\n",
    "    def validation_generator(self,batch_size):\n",
    "        \"\"\"\n",
    "            generator that will feed validation batches during training \n",
    "        \"\"\"\n",
    "        inputs = []\n",
    "        targets = []\n",
    "        batchcount = 0\n",
    "        while True:\n",
    "            #for image_id in self.validation_indices:\n",
    "            # sample real image\n",
    "            image_id = np.random.choice(self.validation_indices,p=self.validation_sample_probs)\n",
    "            real_image = np.load('data/train/img/train_{}.npy'.format(image_id) )\n",
    "\n",
    "            image = self.prepare_test_image(np.copy(real_image))\n",
    "\n",
    "            inputs.append(image)\n",
    "\n",
    "            # get corresponding label \n",
    "            targets.append(self.labels[image_id])\n",
    "\n",
    "            batchcount += 1\n",
    "            if batchcount > batch_size:\n",
    "                X = np.array(inputs)\n",
    "                y = np.array(targets, dtype=np.uint8)\n",
    "                yield (X, y)\n",
    "                inputs = []\n",
    "                targets = []\n",
    "                batchcount = 0           \n",
    "    \n",
    "    def show_class_distribution(self): \n",
    "        fig,axes=plt.subplots(figsize=(30,15))\n",
    "        class_probs=np.mean(self.labels, axis=0)\n",
    "        axes.bar(self.label_names,  class_probs)\n",
    "        axes.tick_params(axis='both', which='major', labelsize=30)\n",
    "        for tick in axes.xaxis.get_major_ticks():\n",
    "            tick.label.set_rotation('vertical')\n",
    "        plt.suptitle('Class distribution within the training data.', fontsize=50)\n",
    "        fig.show()\n",
    "        \n",
    "    def show_training_sampling_distribution(self): \n",
    "        fig,axes=plt.subplots(figsize=(30,15))\n",
    "        class_probs=np.mean(self.labels, axis=0)\n",
    "        axes.bar(self.label_names,  self.sampling_check/self.times_sampled)\n",
    "        axes.tick_params(axis='both', which='major', labelsize=30)\n",
    "        for tick in axes.xaxis.get_major_ticks():\n",
    "            tick.label.set_rotation('vertical')\n",
    "        plt.suptitle('Number of times each class was sampled during training.', fontsize=50)\n",
    "        fig.show()\n",
    "    \n",
    "    def get_class_distribution(self):\n",
    "        return np.mean(self.labels, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing data generated by Classification Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = {\n",
    "    'train_fraction': 0.9,\n",
    "    'input_shape': (224, 224),\n",
    "    'augmentation': True, \n",
    "    'uniform_sample_probabilities': False\n",
    "}\n",
    "ds = Dataset_Classification(dataset_config)\n",
    "ds.show_class_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet50 preprocessor \n",
    "ds.feed_preprocess_function(tf.keras.applications.resnet_v2.preprocess_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = ipywidgets.IntText(min=0, max=ds.get_train_set_size(), value=0, label='image_id')\n",
    "option = ipywidgets.Dropdown(\n",
    "    options=['train', 'test'],\n",
    "    value='train',\n",
    "    description='train or test:',\n",
    "    disabled=False,\n",
    ")\n",
    "interact(ds.view_preprocessed_image,  image_id=image_id, option=option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_id = ipywidgets.IntText(min=0, max=ds.get_train_set_size(), value=0, label='image_id')\n",
    "interact(ds.view_possible_augmentations,  image_id=image_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset class for segmentation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Segmentation(Dataset_Classification): \n",
    "    \"\"\"\n",
    "     A dataset class usefull when training a classification model. \n",
    "    \"\"\"\n",
    "    def __init__(self, config): \n",
    "        self.config = config\n",
    "    \n",
    "        \n",
    "        # set labels in a usefull format\n",
    "        self._classification_labels()\n",
    "        \n",
    "         # initialize\n",
    "        self.initialize()\n",
    "      \n",
    "    def prepare_image(self, image, mask): \n",
    "        \"\"\"\n",
    "            Function that performs all necessary steps from input image to image passed during trainnig. \n",
    "            This method should be overwritten depending on the model used.\n",
    "        \"\"\"\n",
    "        h,w,c=image.shape\n",
    "        # resize manually, when augmentation is turned on a random crop will be done 100% of times.\n",
    "        #if not self.config['augmentation'] or h < self.config['input_shape'][0]or w < self.config['input_shape'][1]:\n",
    "        image = self.reshape(image)\n",
    "        mask=self.reshape(mask)\n",
    "\n",
    "        # augment if augmentation is turned on \n",
    "        if self.config['augmentation']:\n",
    "#             print('Augmentation enabled: check if combination of preprocessor and augmentation makes sence')\n",
    "            transformed=self.augment(image=image, mask=mask)\n",
    "            image=transformed['image']\n",
    "            mask=transformed['mask']\n",
    "        # preprocess \n",
    "        image = self.preprocessor(image)\n",
    "        return image, mask\n",
    "    \n",
    "\n",
    "    def prepare_test_image(self, image, mask): \n",
    "        \"\"\"\n",
    "             Same as prepare_image but without augmentation\n",
    "        \"\"\"\n",
    "        h,w,c=image.shape\n",
    "        # resize manually, when augmentation is turned on a random crop will be done 100% of times.\n",
    "        #if not self.config['augmentation'] or h < self.config['input_shape'][0]or w < self.config['input_shape'][1]:\n",
    "        image = self.reshape(image)\n",
    "        mask=self.reshape(mask)\n",
    "        \n",
    "        # preprocess \n",
    "        image = self.preprocessor(image)\n",
    "        return image, mask \n",
    "    \n",
    "    def view_preprocessed_image(self, image_id, option='train'): \n",
    "        \"\"\"\n",
    "            Shows the original, preprocessed and final mask used for training.\n",
    "        \"\"\"\n",
    "        assert hasattr(self, 'preprocessor'), 'set a preprocessor function before using this.'\n",
    "        \n",
    "        # get image \n",
    "        if option=='train':\n",
    "            # get image \n",
    "            real_image = np.load('data/train/img/train_{}.npy'.format(image_id) )\n",
    "            mask = np.load('data/train/seg/train_{}.npy'.format(image_id))\n",
    "            label_name=self.class_name_per_image[image_id]\n",
    "        else: \n",
    "            real_image = np.load('data/test/img/test_{}.npy'.format(image_id) )\n",
    "            mask = np.load('data/test/seg/test_{}.npy'.format(image_id))\n",
    "            label_name='Not labelled'\n",
    "        image=np.copy(real_image)\n",
    "        \n",
    "        image, mask = self.prepare_image(image, mask)\n",
    "        \n",
    "    \n",
    "    \n",
    "        # print some info \n",
    "        print('original image:')\n",
    "        print('-original_shape:', real_image.shape)\n",
    "        print('-dtype:', real_image.dtype)\n",
    "        print('-min value:', np.min(real_image))\n",
    "        print('-max value:', np.max(real_image))\n",
    "        \n",
    "        print('final image:')\n",
    "        print('-final shape:', image.shape)\n",
    "        print('-dtype:', image.dtype)\n",
    "        print('-min value:', np.min(image))\n",
    "        print('-max value:', np.max(image))\n",
    "        \n",
    "        \n",
    "        # show figure \n",
    "        fig, axes = plt.subplots(1,3, figsize=(30,15))\n",
    "        axes[0].imshow(real_image)\n",
    "        axes[0].set_title('Original image', fontsize=50)\n",
    "        \n",
    "        axes[1].imshow(image) # clip it to [0,1] range\n",
    "        axes[1].set_title('preprocessed_image', fontsize=50)\n",
    "        \n",
    "        axes[2].imshow(mask) # clip it to [0,1] range\n",
    "        axes[2].set_title('Segmentation mask', fontsize=50)\n",
    "        \n",
    "        plt.suptitle('label: {}'.format(label_name), fontsize=50)\n",
    "        fig.show()\n",
    "        \n",
    "    def view_possible_augmentations(self, image_id): \n",
    "        fig, axes = plt.subplots(4,4, figsize=(60,30))\n",
    "        real_image = np.load('data/train/img/train_{}.npy'.format(image_id) )\n",
    "        mask = np.load('data/train/seg/train_{}.npy'.format(image_id))\n",
    "            \n",
    "        plt.suptitle('original image is on the bottom right', fontsize=50)\n",
    "        for ax in axes.flat: \n",
    "            transformed = self.augment(image=real_image, mask=mask)\n",
    "            new_image=transformed['image']\n",
    "            new_mask=transformed['mask']\n",
    "            ax.imshow(new_image, alpha=1)\n",
    "            ax.imshow(new_mask, alpha=0.2)\n",
    "            ax.axis('off')\n",
    "        axes[0,0] = plt.imshow(real_image)\n",
    "        fig.show()\n",
    "        \n",
    "        \n",
    "    \n",
    "    def train_generator(self,batch_size):\n",
    "        \"\"\"\n",
    "            generator that will feed training batches during training \n",
    "        \"\"\"\n",
    "        inputs = []\n",
    "        targets = []\n",
    "        batchcount = 0\n",
    "        while True:\n",
    "            for image_id in self.train_indices:\n",
    "                # sample real image\n",
    "                real_image = np.load('data/train/img/train_{}.npy'.format(image_id))\n",
    "                mask = np.load('data/train/seg/train_{}.npy'.format(image_id))\n",
    "                \n",
    "                image, segmask = self.prepare_image(real_image, mask)\n",
    "                inputs.append(image)\n",
    "                targets.append(segmask)\n",
    "\n",
    "                batchcount += 1\n",
    "                if batchcount > batch_size:\n",
    "                    X = np.array(inputs)\n",
    "                    y = np.array(targets)\n",
    "                    yield (X, y)\n",
    "                    inputs = []\n",
    "                    targets = []\n",
    "                    batchcount = 0\n",
    "\n",
    "    def validation_generator(self,batch_size):\n",
    "        \"\"\"\n",
    "            generator that will feed validation batches during training \n",
    "        \"\"\"\n",
    "        inputs = []\n",
    "        targets = []\n",
    "        batchcount = 0\n",
    "        while True:\n",
    "            for image_id in self.validation_indices:\n",
    "                # sample real image\n",
    "                real_image = np.load('data/train/img/train_{}.npy'.format(image_id))\n",
    "                mask = np.load('data/train/seg/train_{}.npy'.format(image_id) )\n",
    "                \n",
    "                image, segmask = self.prepare_test_image(real_image, mask)\n",
    "                inputs.append(image)\n",
    "                targets.append(segmask)\n",
    "\n",
    "                batchcount += 1\n",
    "                if batchcount > batch_size:\n",
    "                    X = np.array(inputs)\n",
    "                    y = np.array(targets)\n",
    "                    yield (X, y)\n",
    "                    inputs = []\n",
    "                    targets = []\n",
    "                    batchcount = 0           \n",
    "    \n",
    "    def show_class_distribution(self): \n",
    "        fig,axes=plt.subplots(figsize=(30,15))\n",
    "        class_probs=np.mean(self.labels, axis=0)\n",
    "        axes.bar(self.label_names,  class_probs)\n",
    "        axes.tick_params(axis='both', which='major', labelsize=30)\n",
    "        for tick in axes.xaxis.get_major_ticks():\n",
    "            tick.label.set_rotation('vertical')\n",
    "        plt.suptitle('Class distribution within the training data.', fontsize=50)\n",
    "        fig.show()\n",
    "    \n",
    "    def get_class_distribution(self):\n",
    "        return np.mean(self.labels, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing data generated by Segmentation Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = {\n",
    "    'train_fraction': 0.9,\n",
    "    'input_shape': (224, 224),\n",
    "    'augmentation': True, \n",
    "    'uniform_sample_probabilities':True\n",
    "}\n",
    "ds = Dataset_Segmentation(dataset_config)\n",
    "\n",
    "ds.feed_preprocess_function(lambda x: x/255.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = ipywidgets.IntText(min=0, max=ds.get_train_set_size(), value=0, label='image_id')\n",
    "option = ipywidgets.Dropdown(\n",
    "    options=['train', 'test'],\n",
    "    value='train',\n",
    "    description='train or test:',\n",
    "    disabled=False,\n",
    ")\n",
    "interact(ds.view_preprocessed_image,  image_id=image_id, option=option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = ipywidgets.IntText(min=0, max=ds.get_train_set_size(), value=0, label='image_id')\n",
    "interact(ds.view_possible_augmentations,  image_id=image_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.261504,
     "end_time": "2021-03-29T09:05:17.563178",
     "exception": false,
     "start_time": "2021-03-29T09:05:17.301674",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Image classification\n",
    "The goal here is simple: implement a classification CNN and train it to recognise all 20 classes (and/or background) using the training set and compete on the test set (by filling in the classification columns in the test dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T19:31:31.868221Z",
     "start_time": "2021-04-26T19:31:30.107220Z"
    },
    "execution": {
     "iopub.execute_input": "2021-03-29T09:05:18.200397Z",
     "iopub.status.busy": "2021-03-29T09:05:18.199018Z",
     "iopub.status.idle": "2021-03-29T09:05:21.740912Z",
     "shell.execute_reply": "2021-03-29T09:05:21.741375Z"
    },
    "papermill": {
     "duration": 3.860357,
     "end_time": "2021-03-29T09:05:21.741571",
     "exception": false,
     "start_time": "2021-03-29T09:05:17.881214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RandomClassificationModel:\n",
    "    \"\"\"\n",
    "    Random classification model: \n",
    "        - generates random labels for the inputs based on the class distribution observed during training\n",
    "        - assumes an input can have multiple labels\n",
    "    \"\"\"\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Adjusts the class ratio variable to the one observed in y. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: list of arrays - n x (height x width x 3)\n",
    "        y: list of arrays - n x (nb_classes)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        self.distribution = np.mean(y, axis=0)\n",
    "        print(\"Setting class distribution to:\\n{}\".format(\"\\n\".join(f\"{label}: {p}\" for label, p in zip(labels, self.distribution))))\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts for each input a label.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X: list of arrays - n x (height x width x 3)\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        y_pred: list of arrays - n x (nb_classes)\n",
    "        \"\"\"\n",
    "        np.random.seed(0)\n",
    "        return [np.array([int(np.random.rand() < p) for p in self.distribution]) for _ in X]\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        return self.predict(X)\n",
    "    \n",
    "model = RandomClassificationModel()\n",
    "model.fit(train_df[\"img\"], train_df[labels])\n",
    "test_df.loc[:, labels] = model.predict(test_df[\"img\"])\n",
    "test_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet50 as a first try for classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-04-26T19:32:04.869Z"
    },
    "code_folding": [
     18,
     30,
     43,
     163,
     181,
     215,
     279,
     285,
     390,
     432,
     479,
     533,
     566,
     581,
     592,
     613,
     626,
     641,
     664,
     697,
     705,
     741,
     763,
     766,
     794
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "\n",
    "class ResNetClassifactionModel(RandomClassificationModel): \n",
    "    def __init__(self, config): \n",
    "        self.config = config \n",
    "        self.config_head = config['head_model']\n",
    "        self.project_name = 'resnet_50'\n",
    "        \n",
    "        # initialize dataset\n",
    "        self.dataset = Dataset_Classification(config['dataset'])\n",
    "        \n",
    "        # feed preprocessor to dataset\n",
    "        print('Feeding resnet50 preprocess function to dataset class')\n",
    "        self.dataset.feed_preprocess_function(tf.keras.applications.resnet_v2.preprocess_input)\n",
    "        \n",
    "        # check if some configurations make sense \n",
    "        assert len(self.config_head['head_model_units']) == len(self.config_head['add_dropout']), 'head_models_units and add_dropout list should have same size'\n",
    "    \n",
    "    \n",
    "    def set_config(self, config):\n",
    "        self.config = config \n",
    "        self.config_head = config['head_model']\n",
    "        self.dataset = Dataset_Classification(config['dataset'])\n",
    "        assert len(self.config_head['head_model_units']) == len(self.config_head['add_dropout']), 'head_models_units and add_dropout list should have same size'\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # \n",
    "        \n",
    "        if len(X.shape) == 1: \n",
    "            # X is a batch of images prepare all of them and create batch. \n",
    "            batch = np.array([self.dataset.prepare_test_image(im) for im in X])\n",
    "            print(batch.shape)\n",
    "            \n",
    "            y = model.predict(batch)\n",
    "        else: \n",
    "            # X is a single image \n",
    "            batch = self.dataset.prepare_test_image(X)\n",
    "            batch = np.expand_dims(batch, axis=0)\n",
    "            print(batch.shape)\n",
    "            y = model.predict(batch)\n",
    "            \n",
    "        y = np.squeeze(y)\n",
    "        print(y)\n",
    "        print(self.dataset.label_names)\n",
    "        label_idx = np.where(y==1.)\n",
    "        print(label_idx)\n",
    "        return self.dataset.label_names[label_idx]\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def build(self): \n",
    "        \"\"\"\n",
    "            Builds the model \n",
    "        \"\"\"\n",
    "        # define a resnet50 base model\n",
    "        resnet50 = tf.keras.applications.ResNet50V2(\n",
    "                    include_top=False,\n",
    "                    weights=self.config['weights'],\n",
    "                    input_shape=self.config['input_shape'],\n",
    "                        )\n",
    "    \n",
    "        self.base_model = resnet50\n",
    "        \n",
    "        # define a head model\n",
    "        head_model=resnet50.output\n",
    "        head_model=tf.keras.layers.AveragePooling2D(pool_size=(5,5))(head_model)\n",
    "        head_model=tf.keras.layers.Flatten()(head_model)\n",
    "        \n",
    "        for (nbr_units, dropout) in zip(self.config_head['head_model_units'], self.config_head['add_dropout']): \n",
    "            head_model=tf.keras.layers.Dense(nbr_units, activation=self.config_head['activation'])(head_model)\n",
    "            if dropout:\n",
    "                head_model=tf.keras.layers.Dropout(0.4)(head_model)\n",
    "        \n",
    "        head_model=tf.keras.layers.Dense(self.config['nbr_classes'], activation='sigmoid')(head_model)\n",
    "        \n",
    "        self.head_model = head_model\n",
    "                \n",
    "            \n",
    "        # combine both models \n",
    "        self.model = tf.keras.Model(self.base_model.input, self.head_model)\n",
    "        \n",
    "    def weighted_categorical_crossentropy(self,weights):\n",
    "        \"\"\"\n",
    "        A weighted version of keras.objectives.categorical_crossentropy\n",
    "\n",
    "        Variables:\n",
    "            weights: numpy array of shape (C,) where C is the number of classes\n",
    "\n",
    "        Usage:\n",
    "            weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "            loss = weighted_categorical_crossentropy(weights)\n",
    "            model.compile(loss=loss,optimizer='adam')\n",
    "        \"\"\"\n",
    "\n",
    "        weights = K.variable(weights)\n",
    "\n",
    "        def loss(y_true, y_pred):\n",
    "            # scale predictions so that the class probas of each sample sum to 1\n",
    "            y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "            # clip to prevent NaN's and Inf's\n",
    "            y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "            # calc\n",
    "            loss = y_true * K.log(y_pred) * weights\n",
    "            loss = -K.sum(loss, -1)\n",
    "            return loss\n",
    "\n",
    "        return loss\n",
    "        \n",
    "    def compile_model(self): \n",
    "        # optimizer\n",
    "#         optimizer = tf.keras.optimizers.Adam(\n",
    "#                                 learning_rate=self.config['train_parameters']['learning_rate'],\n",
    "#                                 beta_1=0.9,\n",
    "#                                 beta_2=0.999,\n",
    "#                                 epsilon=1e-07,\n",
    "#                                 amsgrad=False,\n",
    "#                                 name=\"Adam\",\n",
    "#                             )\n",
    "        optimizer = tf.keras.optimizers.SGD(\n",
    "                learning_rate=self.config['train_parameters']['learning_rate'], momentum=0.9,\n",
    "                nesterov=False, name=\"SGD\"\n",
    "            )\n",
    "\n",
    "        # metric\n",
    "        metrics = [tf.keras.metrics.CategoricalAccuracy(),\n",
    "                  tf.keras.metrics.TopKCategoricalAccuracy(k=3, name='top 3 categorical acccuracy'), \n",
    "                  tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='top 5 categorical acccuracy')\n",
    "                  ]\n",
    "    \n",
    "    \n",
    "\n",
    "#         loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "#                 from_logits=True,\n",
    "#                 label_smoothing=0,\n",
    "#                 reduction=\"auto\",\n",
    "#                 name=\"categorical_crossentropy_loss\",\n",
    "#              )\n",
    "        #loss='sparse_categorical_crossentropy'\n",
    "        #oss = 'categorical_crossentropy'\n",
    "        \n",
    "        #loss = self.weighted_categorical_crossentropy(np.ones(20)/20)\n",
    "        \n",
    "        #loss=tf.keras.losses.KLDivergence(reduction=\"auto\", name=\"kl_divergence\")\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(from_logits=False, label_smoothing=0,name='binary_crossentropy')\n",
    "\n",
    "\n",
    "        self.model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "        \n",
    "    def train(self, name_run, notes, tags):\n",
    "        # build generator and discriminator models \n",
    "        gpus = tf.config.list_physical_devices('GPU')\n",
    "        if gpus:\n",
    "            try:\n",
    "                # Currently, memory growth needs to be the same across GPUs\n",
    "                for gpu in gpus:\n",
    "                    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "                logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "                print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "            except RuntimeError as e:\n",
    "                # Memory growth must be set before GPUs have been initialized\n",
    "                print(e)\n",
    "            \n",
    "        # setup logging\n",
    "        if self.config['logging_wandb']:\n",
    "            # w&b \n",
    "            wandb.init(name=name_run, \n",
    "                   project=self.project_name,\n",
    "                   notes=notes, \n",
    "                   tags=tags,\n",
    "                   entity='cv-task-2')\n",
    "\n",
    "            # save usefull config to w&b\n",
    "            wandb.config.learning_rate = self.config['train_parameters']['learning_rate']\n",
    "            wandb.config.batch_size = self.config['train_parameters']['batch_size']\n",
    "            wandb.config.epochs = self.config['train_parameters']['epochs']\n",
    "            wandb.config.steps_per_epoch = self.config['train_parameters']['steps_per_epoch']\n",
    "            \n",
    "            \n",
    "        # build model \n",
    "        self.build()\n",
    "        #self.model.summary()\n",
    "        \n",
    "        # set model parts trainable or not\n",
    "        if self.config['train_base_model'] == False: \n",
    "            print('freezing base model layers')\n",
    "            for layer in self.base_model.layers:\n",
    "                layer.trainable = False\n",
    "        if self.config['train_head_model'] == False: \n",
    "            print('freezing head model layers')\n",
    "            for layer in self.head_model.layers:\n",
    "                layer.trainable = False\n",
    "        \n",
    "        \n",
    "        # compile model\n",
    "        self.compile_model()\n",
    "        \n",
    "        if self.config['logging_wandb']:\n",
    "            # set save_model true if you want wandb to upload weights once run has finished (takes some time)\n",
    "            clbcks = [WandbCallback(save_model=False)]\n",
    "        else: \n",
    "            clbcks = []\n",
    "\n",
    "        \n",
    "        # start training \n",
    "        history=self.model.fit(\n",
    "                    x = self.dataset.train_generator(batch_size=self.config['train_parameters']['batch_size']),\n",
    "                    steps_per_epoch = self.config['train_parameters']['steps_per_epoch'],\n",
    "                    epochs=self.config['train_parameters']['epochs'], \n",
    "                    validation_data=self.dataset.validation_generator(batch_size=self.config['train_parameters']['batch_size']),\n",
    "                    validation_steps=20, \n",
    "                    callbacks=clbcks\n",
    "        )\n",
    "        \n",
    "        #workers=multiprocessing.cpu_count(),\n",
    "        #use_multiprocessing=True,\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T19:26:21.498861Z",
     "start_time": "2021-04-26T19:26:21.479091Z"
    },
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'name': 'resnet50 KL divergence',\n",
    "    'logging_wandb': False,  #nice tool for tracking a run. make and account on wandb.ai and I will add you to this project\n",
    "    'weights': None, # 'imagenet', #None, \n",
    "    'nbr_classes': 20,\n",
    "    'input_shape': (224, 224, 3),\n",
    "    'train_base_model': True, # whether to train the head and or base model\n",
    "    'train_head_model': True, \n",
    "    'train_parameters': {\n",
    "        'epochs': 5,\n",
    "        'batch_size': 64,\n",
    "        'learning_rate': 0.001, \n",
    "        'steps_per_epoch': 1000\n",
    "    },\n",
    "    'dataset': {\n",
    "        'train_fraction': 0.9,\n",
    "        'input_shape': (224, 224),\n",
    "        'augmentation': True, # whether to augment images or not\n",
    "        'uniform_sample_probabilities': False\n",
    "    },\n",
    "    'head_model': {\n",
    "        'head_model_units': [512, 512], \n",
    "        'add_dropout':      [False, False],\n",
    "        'activation': 'relu'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-04-26T19:27:08.956Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RC = ResNetClassifactionModel(config)\n",
    "RC.dataset.feed_preprocess_function(lambda x:x/255.0)\n",
    "#RC.config = config\n",
    "# RC.build()\n",
    "# RC.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T18:58:57.106590Z",
     "start_time": "2021-04-26T18:58:57.090366Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "name_run='resnet_50 KL divergence'\n",
    "notes='Binary crossentropy'\n",
    "tags = ['resnet50', 'head = [1024, 1024]', 'head = [True, True]', 'Augmentation applied', 'loss: KLDivergence']\n",
    "RC.set_config(config)\n",
    "RC.train(name_run, notes, tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RC.dataset.show_training_sampling_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RC.dataset.show_class_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr=5\n",
    "test_data=test_df[\"img\"].to_numpy()\n",
    "batch = test_data[nbr]\n",
    "print(batch.shape)\n",
    "# idx = np.random.randint(10,255, 3*500*300)\n",
    "# batch = idx.reshape(300,500,3)\n",
    "print(batch.shape)\n",
    "plt.imshow(batch)\n",
    "\n",
    "# RC.build()\n",
    "# RC.model.load_weights('resnet50_heads_1024_1024.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RC.predict(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(ResNetClassifactionModel): \n",
    "    def __init__(self, config):\n",
    "        self.config = config \n",
    "        self.config_head = config['head_model']\n",
    "        self.project_name = 'custom'\n",
    "        \n",
    "        # initialize dataset\n",
    "        self.dataset = Dataset_Classification(config['dataset'])\n",
    "        \n",
    "        # feed preprocessor to dataset\n",
    "        print('Feeding resnet50 preprocess function to dataset class')\n",
    "        self.dataset.feed_preprocess_function(lambda x: x/255.0)\n",
    "    \n",
    "    def build(self):\n",
    "        print('simple cnn')\n",
    "        model = keras.models.Sequential([\n",
    "            keras.layers.Conv2D(64,7, activation='relu', padding=\"same\", \n",
    "                                input_shape=self.config['input_shape']), \n",
    "            keras.layers.MaxPooling2D(2), \n",
    "            keras.layers.Conv2D(128,3,activation='relu', padding='same'),\n",
    "            keras.layers.Conv2D(128,3,activation='relu', padding='same'),\n",
    "            keras.layers.MaxPooling2D(2),\n",
    "            keras.layers.Conv2D(256,3,activation='relu', padding='same'),\n",
    "            keras.layers.Conv2D(256,3,activation='relu', padding='same'),\n",
    "            keras.layers.MaxPooling2D(2), \n",
    "\n",
    "            keras.layers.Flatten(), \n",
    "            keras.layers.Dense(128, activation='relu'), \n",
    "            keras.layers.Dropout(0.5), \n",
    "            keras.layers.Dense(64, activation='relu'), \n",
    "            keras.layers.Dropout(0.5), \n",
    "            keras.layers.Dense(self.config['nbr_classes'], activation='softmax')\n",
    "            ])\n",
    "        self.model=model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'name': 'resnet50 KL divergence',\n",
    "    'logging_wandb': False,  #nice tool for tracking a run. make and account on wandb.ai and I will add you to this project\n",
    "    'weights': 'imagenet', #None, \n",
    "    'nbr_classes': 20,\n",
    "    'input_shape': (224, 224, 3),\n",
    "    'train_base_model': True, # whether to train the head and or base model\n",
    "    'train_head_model': True, \n",
    "    'train_parameters': {\n",
    "        'epochs': 20,\n",
    "        'batch_size': 64,\n",
    "        'learning_rate': 0.01, \n",
    "        'steps_per_epoch': 100\n",
    "    },\n",
    "    'dataset': {\n",
    "        'train_fraction': 0.9,\n",
    "        'input_shape': (224, 224),\n",
    "        'augmentation': True # whether to augment images or not\n",
    "    },\n",
    "    'head_model': {\n",
    "        'head_model_units': [1024, 1024], \n",
    "        'add_dropout':      [True, True],\n",
    "        'activation': 'relu'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Custom = CustomModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_run=''\n",
    "notes=''\n",
    "tags = ['custom']\n",
    "Custom.train(name_run, notes, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG19ClassifactionModel(ResNetClassifactionModel): \n",
    "    def __init__(self, config): \n",
    "        self.config = config \n",
    "        self.config_head = config['head_model']\n",
    "        \n",
    "        self.project_name = 'VGG19'\n",
    "        \n",
    "        # initialize dataset\n",
    "        self.dataset = Dataset_Classification(config['dataset'])\n",
    "        \n",
    "        # feed preprocessor to dataset\n",
    "        print('Feeding vgg19 preprocess function to dataset class')\n",
    "        self.dataset.feed_preprocess_function(tf.keras.applications.vgg19.preprocess_input)\n",
    "        \n",
    "        # check if some configurations make sense \n",
    "        assert len(self.config_head['head_model_units']) == len(self.config_head['add_dropout']), 'head_models_units and add_dropout list should have same size'\n",
    "        \n",
    "    def build(self): \n",
    "        \"\"\"\n",
    "            Builds the model \n",
    "        \"\"\"\n",
    "        # define a resnet50 base model\n",
    "        VGG19 = tf.keras.applications.VGG19(\n",
    "                    include_top=False,\n",
    "                    weights=self.config['weights'],\n",
    "                    input_shape=self.config['input_shape'],\n",
    "                        )\n",
    "    \n",
    "        self.base_model = VGG19\n",
    "        \n",
    "        # define a head model\n",
    "        head_model=VGG19.output\n",
    "        #head_model=tf.keras.layers.AveragePooling2D(pool_size=(7,7))(head_model)\n",
    "        head_model=tf.keras.layers.Flatten()(head_model)\n",
    "        \n",
    "        for (nbr_units, dropout) in zip(self.config_head['head_model_units'], self.config_head['add_dropout']): \n",
    "            head_model=tf.keras.layers.Dense(nbr_units, activation=self.config_head['activation'])(head_model)\n",
    "            if dropout:\n",
    "                head_model=tf.keras.layers.Dropout(0.2)(head_model)\n",
    "        \n",
    "        head_model=tf.keras.layers.Dense(self.config['nbr_classes'], activation='linear')(head_model)\n",
    "        \n",
    "        self.head_model = head_model\n",
    "                \n",
    "            \n",
    "        # combine both models \n",
    "        self.model = tf.keras.Model(self.base_model.input, self.head_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'name': 'vgg19',\n",
    "    'logging_wandb': False, \n",
    "    'weights': None, \n",
    "    'nbr_classes': 20,\n",
    "    'input_shape': (224, 224, 3),\n",
    "    'train_base_model': True, # whether to train the head and or base model\n",
    "    'train_head_model': True, \n",
    "    'train_parameters': {\n",
    "        'epochs': 10,\n",
    "        'batch_size': 32,\n",
    "        'learning_rate': 0.001, \n",
    "        'steps_per_epoch': 100\n",
    "    },\n",
    "    'dataset': {\n",
    "        'train_fraction': 0.9,\n",
    "        'input_shape': (224, 224),\n",
    "        'augmentation': True # whether to augment images or not\n",
    "    },\n",
    "    'head_model': {\n",
    "        'head_model_units': [2048], \n",
    "        'add_dropout':      [False],\n",
    "        'activation': 'linear'\n",
    "    }\n",
    "}\n",
    "#64, 128, 256, 512, 1024, 2048, 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model=VGG19ClassifactionModel(config)\n",
    "# vgg_model.build()\n",
    "# vgg_model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "name_run='vgg19_'\n",
    "notes='First try for finetuning vgg19 on pretrained imagenet weights. Data augmentation turned on. '\n",
    "tags = ['resnet50', 'head = [2048]', 'head = [False]', 'Augmentation applied']\n",
    "vgg_model.train(name_run, notes, tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = {\n",
    "    'train_fraction': 0.9,\n",
    "    'input_shape': (224, 224),\n",
    "    'augmentation': False\n",
    "}\n",
    "ds = Dataset_Segmentation(dataset_config)\n",
    "# resnet50 preprocessor \n",
    "ds.feed_preprocess_function(lambda x: x/255.0)\n",
    "\n",
    "i = 0\n",
    "for X,y in ds.train_generator(0): \n",
    "    if i > 1: \n",
    "        break \n",
    "    i+=1 \n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "fig, axes = plt.subplots(1,2)\n",
    "axes[0].imshow(X[0])\n",
    "axes[1].imshow(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y[0].shape)\n",
    "print(np.unique(y[0]))\n",
    "idx = np.where(y[0] == 2)\n",
    "zrs = np.zeros(y[0].shape)\n",
    "zrs[idx]=1\n",
    "plt.imshow(zrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "model=tf.keras.applications.ResNet50V2()\n",
    "preds = model.predict(im_pr)\n",
    "tf.keras.applications.imagenet_utils.decode_predictions(\n",
    "    preds, top=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.194695,
     "end_time": "2021-03-29T09:05:22.154564",
     "exception": false,
     "start_time": "2021-03-29T09:05:21.959869",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Semantic segmentation\n",
    "The goal here is to implement a segmentation CNN that labels every pixel in the image as belonging to one of the 20 classes (and/or background). Use the training set to train your CNN and compete on the test set (by filling in the segmentation column in the test dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T09:05:22.577753Z",
     "iopub.status.busy": "2021-03-29T09:05:22.576727Z",
     "iopub.status.idle": "2021-03-29T09:05:34.965517Z",
     "shell.execute_reply": "2021-03-29T09:05:34.966002Z"
    },
    "papermill": {
     "duration": 12.607971,
     "end_time": "2021-03-29T09:05:34.966182",
     "exception": false,
     "start_time": "2021-03-29T09:05:22.358211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RandomSegmentationModel:\n",
    "    \"\"\"\n",
    "    Random segmentation model: \n",
    "        - generates random label maps for the inputs based on the class distributions observed during training\n",
    "        - every pixel in an input can only have one label\n",
    "    \"\"\"\n",
    "    def fit(self, X, Y):\n",
    "        \"\"\"\n",
    "        Adjusts the class ratio variable to the one observed in Y. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: list of arrays - n x (height x width x 3)\n",
    "        Y: list of arrays - n x (height x width)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        self.distribution = np.mean([[np.sum(Y_ == i) / Y_.size for i in range(len(labels) + 1)] for Y_ in Y], axis=0)\n",
    "        print(\"Setting class distribution to:\\nbackground: {}\\n{}\".format(self.distribution[0], \"\\n\".join(f\"{label}: {p}\" for label, p in zip(labels, self.distribution[1:]))))\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts for each input a label map.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X: list of arrays - n x (height x width x 3)\n",
    "             \n",
    "        Returns\n",
    "        -------\n",
    "        Y_pred: list of arrays - n x (height x width)\n",
    "        \"\"\"\n",
    "        np.random.seed(0)\n",
    "        return [np.random.choice(np.arange(len(labels) + 1), size=X_.shape[:2], p=self.distribution) for X_ in X]\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        return self.predict(X)\n",
    "    \n",
    "model = RandomSegmentationModel()\n",
    "model.fit(train_df[\"img\"], train_df[\"seg\"])\n",
    "test_df.loc[:, \"seg\"] = model.predict(test_df[\"img\"])\n",
    "test_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetSegmentationMode(ResNetClassifactionModel): \n",
    "    def __init__(self, config): \n",
    "        self.config=config\n",
    "        self.config_head = config['head_model']\n",
    "        self.output_channels=self.config['nbr_classes'] + 1 # plus one since background is a class\n",
    "        \n",
    "        # initialize dataset\n",
    "        self.dataset = Dataset_Segmentation(config['dataset'])\n",
    "        \n",
    "        # feed preprocessor to dataset\n",
    "        print('Feeding vgg19 preprocess function to dataset class')\n",
    "        self.dataset.feed_preprocess_function(tf.keras.applications.vgg19.preprocess_input)\n",
    "        \n",
    "        self.project_name = 'Unet'\n",
    "        \n",
    "        \n",
    "    ## \n",
    "    def upsample(self, filters, size, apply_dropout=False):\n",
    "        initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "        result = tf.keras.Sequential()\n",
    "        result.add(\n",
    "        tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                        padding='same',\n",
    "                                        kernel_initializer=initializer,\n",
    "                                        use_bias=False))\n",
    "\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "        if apply_dropout:\n",
    "            result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "        result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def compile_model(self): \n",
    "        # optimizer\n",
    "        optimizer = tf.keras.optimizers.Adam(\n",
    "                                learning_rate=self.config['train_parameters']['learning_rate'],\n",
    "                                beta_1=0.9,\n",
    "                                beta_2=0.999,\n",
    "                                epsilon=1e-07,\n",
    "                                amsgrad=False,\n",
    "                                name=\"Adam\",\n",
    "                            )\n",
    "\n",
    "        metrics = ['acc', \n",
    "                  tf.keras.metrics.SparseTopKCategoricalAccuracy(k=3, name='top 3 categorical acccuracy'), \n",
    "                  tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name='top 5 categorical acccuracy')\n",
    "                  ]\n",
    "\n",
    "\n",
    "        loss=loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "\n",
    "        self.model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "        \n",
    "    def build(self):\n",
    "        ## base model\n",
    "        base_model = tf.keras.applications.MobileNetV2(input_shape=self.config['input_shape'], include_top=False)\n",
    "\n",
    "        # Use the activations of these layers\n",
    "        layer_names = [\n",
    "            'block_1_expand_relu',   # 64x64\n",
    "            'block_3_expand_relu',   # 32x32\n",
    "            'block_6_expand_relu',   # 16x16\n",
    "            'block_13_expand_relu',  # 8x8\n",
    "            'block_16_project',      # 4x4\n",
    "        ]\n",
    "        base_model_outputs = [base_model.get_layer(name).output for name in layer_names]\n",
    "\n",
    "        # Create the feature extraction model\n",
    "        down_stack = tf.keras.Model(inputs=base_model.input, outputs=base_model_outputs)\n",
    "\n",
    "        down_stack.trainable = False # hard code it to be not trainable\n",
    "        \n",
    "        self.base_model = down_stack\n",
    "        ## head model\n",
    "        \n",
    "        up_stack = [\n",
    "            self.upsample(512, 3, self.config_head['add_dropout']),  # 4x4 -> 8x8\n",
    "            self.upsample(256, 3, self.config_head['add_dropout']),  # 8x8 -> 16x16\n",
    "            self.upsample(128, 3, self.config_head['add_dropout']),  # 16x16 -> 32x32\n",
    "            self.upsample(64, 3, self.config_head['add_dropout']),   # 32x32 -> 64x64\n",
    "        ]\n",
    "        \n",
    "        inputs = tf.keras.layers.Input(shape=self.config['input_shape'])\n",
    "\n",
    "        # Downsampling through the model\n",
    "        skips = down_stack(inputs)\n",
    "        x = skips[-1]\n",
    "        skips = reversed(skips[:-1])\n",
    "\n",
    "        # Upsampling and establishing the skip connections\n",
    "        for up, skip in zip(up_stack, skips):\n",
    "            x = up(x)\n",
    "            concat = tf.keras.layers.Concatenate()\n",
    "            x = concat([x, skip])\n",
    "\n",
    "        # This is the last layer of the model\n",
    "        last = tf.keras.layers.Conv2DTranspose(\n",
    "            self.output_channels, 3, strides=2,\n",
    "            padding='same')  #64x64 -> 128x128\n",
    "\n",
    "        x = last(x)\n",
    "\n",
    "        self.model = tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unet_config = {\n",
    "    'name': 'Unet',\n",
    "    'logging_wandb': True, \n",
    "    'nbr_classes': 20,\n",
    "    'train_base_model': False, # whether to train the head and or base model\n",
    "    'train_head_model': True, # not defined here\n",
    "    'input_shape': (224, 224, 3),\n",
    "    'train_parameters': {\n",
    "        'epochs': 10,\n",
    "        'batch_size': 64,\n",
    "        'learning_rate': 0.001, \n",
    "        'steps_per_epoch': 1000\n",
    "    },\n",
    "    'dataset': {\n",
    "        'train_fraction': 0.9,\n",
    "        'input_shape': (224, 224),\n",
    "        'augmentation': True # whether to augment images or not\n",
    "    },\n",
    "    'head_model': {\n",
    "        'add_dropout': True,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unet = UnetSegmentationMode(Unet_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "name_run='Unet 1'\n",
    "notes='Changed configurations, higher batch size, more steps per epoch'\n",
    "tags = ['unet', 'Augmentation applied', 'dropout added']\n",
    "Unet.train(name_run, notes, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.193218,
     "end_time": "2021-03-29T09:05:35.361389",
     "exception": false,
     "start_time": "2021-03-29T09:05:35.168171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Submit to competition\n",
    "You don't need to edit this section. Just use it at the right position in the notebook. See the definition of this function in Sect. 1.3 for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T09:05:35.750969Z",
     "iopub.status.busy": "2021-03-29T09:05:35.750253Z",
     "iopub.status.idle": "2021-03-29T09:07:06.152716Z",
     "shell.execute_reply": "2021-03-29T09:07:06.153236Z"
    },
    "papermill": {
     "duration": 90.600773,
     "end_time": "2021-03-29T09:07:06.153425",
     "exception": false,
     "start_time": "2021-03-29T09:05:35.552652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_submission(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.197143,
     "end_time": "2021-03-29T09:07:06.546217",
     "exception": false,
     "start_time": "2021-03-29T09:07:06.349074",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Adversarial attack\n",
    "For this part, your goal is to fool your classification and/or segmentation CNN, using an *adversarial attack*. More specifically, the goal is build a CNN to perturb test images in a way that (i) they look unperturbed to humans; but (ii) the CNN classifies/segments these images in line with the perturbations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.195133,
     "end_time": "2021-03-29T09:07:06.938031",
     "exception": false,
     "start_time": "2021-03-29T09:07:06.742898",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Discussion\n",
    "Finally, take some time to reflect on what you have learned during this assignment. Reflect and produce an overall discussion with links to the lectures and \"real world\" computer vision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-venv",
   "language": "python",
   "name": "cv-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 178.155457,
   "end_time": "2021-03-29T09:07:09.396364",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-03-29T09:04:11.240907",
   "version": "2.2.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
